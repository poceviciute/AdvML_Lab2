---
title: "Report_Lab2_Milda"
author: "Milda Poceviciute"
date: "27 September 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r,echo=FALSE,warning=FALSE,message=FALSE}
library(HMM)
set.seed(12345)
```

## Question 1

Based on the scenario described in the lab instruction, the hidden Markov model (HMM) is:

```{r, echo=FALSE}
# Create states
grid_states <- c(paste0("Sector ",1:10))
Readings <- grid_states

# Building states probabilities
Tprobs1 <- c(rep.int(0.5,2),rep.int(0,8))
Tprobs2 <- c(0,rep.int(0.5,2),rep.int(0,7))
Tprobs3 <- c(rep.int(0,2),rep.int(0.5,2),rep.int(0,6))
Tprobs4 <- c(rep.int(0,3),rep.int(0.5,2),rep.int(0,5))
Tprobs5 <- c(rep.int(0,4),rep.int(0.5,2),rep.int(0,4))
Tprobs6 <- c(rep.int(0,5),rep.int(0.5,2),rep.int(0,3))
Tprobs7 <- c(rep.int(0,6),rep.int(0.5,2),rep.int(0,2))
Tprobs8 <- c(rep.int(0,7),rep.int(0.5,2),rep.int(0,1))
Tprobs9 <- c(rep.int(0,8),rep.int(0.5,2))
Tprobs10 <- c(0.5,rep.int(0,8),0.5)

transProbs <- matrix(c(Tprobs1,Tprobs2,Tprobs3,Tprobs4,Tprobs5,Tprobs6,Tprobs7,Tprobs8,Tprobs9,Tprobs10),ncol=10,nrow=10,byrow = TRUE)

# Building Observed readings probabilities
probs1 <- c(rep.int(0.2,3),rep.int(0,5),rep.int(0.2,2))
probs2 <- c(rep.int(0.2,4),rep.int(0,5),rep.int(0.2,1))
probs3 <- c(rep.int(0.2,5),rep.int(0,5))
probs4 <- c(0,rep.int(0.2,5),rep.int(0,4))
probs5 <- c(0,0,rep.int(0.2,5),rep.int(0,3))
probs6 <- c(rep.int(0,3),rep.int(0.2,5),rep.int(0,2))
probs7 <- c(rep.int(0,4),rep.int(0.2,5),rep.int(0,1))
probs8 <- c(rep.int(0,5),rep.int(0.2,5))
probs9 <- c(0.2,rep.int(0,5),rep.int(0.2,4))
probs10 <- c(rep.int(0.2,2),rep.int(0,5),rep.int(0.2,3))

emissProbs <- matrix(c(probs1,probs2,probs3,probs4,probs5,probs6,probs7,probs8,probs9,probs10),ncol=10,nrow=10)

# Initiate HMM

Robot_hmm <- initHMM(States=grid_states, Symbols=Readings, startProbs=rep.int(0.1,10), transProbs=transProbs, emissionProbs=emissProbs)

Robot_hmm

```


## Question 2

In order to simulate from the HMM model from Q1, the function simHMM is used.
```{r}
Robot_path <- simHMM(Robot_hmm,100)
Robot_path
```


## Question 3

Definitions of the filtering and smoothing probability distributions are as follows:

*Filtering*: $p(Z^t|x^{0:t}) = \frac{\alpha(Z^t)}{\sum_{z^t}\alpha(z^t)}$

*Smoothing*: $p(Z^t|x^{0:t}) = \frac{\alpha(Z^t)\beta(Z^t)}{\sum_{z^t}\alpha(z^t)\beta(z^t)}$

In the HMM package, $log(\alpha)$ is returned by the _forward_ while the $log(\beta)$ is returned by the _backward_ functions.

```{r}
robot_probs <- function(hmm,xs){
    # Alpha and Beta
    forward_probs <- forward(hmm = hmm, observation = xs)
    backward_probs <- backward(hmm = hmm, observation = xs)
    
    # Normalising the probabilities 
    e_forw <- exp(forward_probs)
    filter_prob <- prop.table(e_forw,2)

    e_back <- exp(backward_probs)
    smooth_prob <- prop.table(e_forw*e_back,2)
    
    return(list(filter_prob = filter_prob, smooth_prob = smooth_prob))
}

path_finder <- function(line){
    # select the path with the highest probability
    m <- max(line)
    list_m <- which(line == m)
    
    if (length(list_m) != 1){
        # if some hav ethe same highest prob, randomly select one of them
        index <- sample(list_m,1)
    } else {
        index <- list_m
    }
    return(grid_states[index])
}


result3 <- robot_probs(hmm=Robot_hmm,xs=Robot_path$observation)
cat("Filtering probabilities:")
cat("\n")
result3$filter_prob[,1:10]
cat("Smoothing probabilities:")
cat("\n")
result3$smooth_prob[,1:10]
cat("\n")
```

The Viterbi algorithm in HMM package is used to find the most probable path:

```{r}
# The most likely path calculated by the Viterbi Algorithm
viterbi_path <- viterbi(hmm = Robot_hmm, observation = Robot_path$observation)
viterbi_path
```



## Question 4

```{r}
accuracy <- function(pathA, trueP){
    compare <- pathA==trueP
    t <- table(compare)
    accur <- t[2]/(sum(t)) 
    return(list(accuracy=accur,table=t))
}

# Path calculated by hand based on the forward probabilities
filter_path <- apply(result3$filter_prob,2,path_finder)
# Path calculated by hand based on the backward probabilities
smooth_path <- apply(result3$smooth_prob,2,path_finder)
True_path <- Robot_path$states

result_f <- accuracy(filter_path,True_path)
result_v <- accuracy(viterbi_path,True_path)
result_s <- accuracy(smooth_path,True_path)

#get the most probable path
cat("Accuracy of Filtered probability distribution:")
cat("\n")
result_f
cat("Accuracy of Smoothed probability distribution:")
cat("\n")
result_s
cat("Accuracy of the Viterbi algorithm:")
cat("\n")
result_v

```

From the accuracy rates above, I conlcude that the Smoothing probability distribution yields the highest accuracy.

## Question 5

```{r}
sim_probs <- function(hmm,sampleN){
    
    simulation <- simHMM(hmm=hmm,length=sampleN)
    result_probs <- robot_probs(hmm=hmm,xs=simulation$observation )

    # Path calculated by hand based on the forward probabilities
    filter_path2 <- apply(result_probs$filter_prob,2,path_finder)
    # Path calculated by hand based on the backward probabilities
    smooth_path2 <- apply(result_probs$smooth_prob,2,path_finder)
    True_path2 <- simulation$states
    # The most likely path calculated by the Viterbi Algorithm
    viterbi_path2 <- viterbi(hmm = hmm, observation = simulation$observation)

    result_f2 <- accuracy(filter_path2,True_path2)
    result_v2 <- accuracy(viterbi_path2,True_path2)
    result_s2 <- accuracy(smooth_path2,True_path2)

    return(list(result_f=result_f2$accuracy,result_v=result_v2$accuracy,result_s=result_s2$accuracy))
}


question5 <- lapply(rep.int(100,125),sim_probs,hmm=Robot_hmm)

# Extract inner lists for plotting
filter5 <- unname(unlist(lapply(question5, `[`, 1)))
smooth5 <- unname(unlist(lapply(question5, `[`, 2)))
viterbi5 <- unname(unlist(lapply(question5, `[`, 3)))

plot(x=1:125, y = filter5, col="blue",xlab="time",ylab="Accuracy", type="l")
lines(x=1:125,y=smooth5,col="red")
lines(x=1:125,y=viterbi5,col="green")
legend("bottomright",c("Filtering", "Smoothing", "Viterbi"), col = c("blue","red","green"), lty = c(1, 1, 1))

```

## Question 6

The lower the Shannon entropy, the more information distribution contains.


```{r}
entropy <- apply(result3$filter_prob,2,entropy.empirical)

plot(entropy, type="l")

```


## Question 7


$P(Z^{t+1}|X^{1:t})$

```{r}
Z100 <- matrix(rep(result3$filter_prob[,100],10),nrow=10,ncol=10)
Z_101 <- t(transProbs) %*% Z100[,1]
```


#Appendix

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```





